import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, Subset
import torch.optim as optim
from torchvision.models.segmentation.deeplabv3 import DeepLabHead
import timm
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings
import glob
import os
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib.font_manager")
import cv2
from scipy.interpolate import interp1d
from PIL import Image
import torchvision.transforms as T
from tqdm import tqdm


# =============================================
# HRNetìœ¼ë¡œ feature map ìƒì„± í›„ DeepLabV3+ë¡œ ë¶„ì„
# =============================================
'''
1. HRNet
ê³ í•´ìƒë„ feature mapì„ ìœ ì§€í•œ ì±„ë¡œ ì²˜ë¦¬í•˜ëŠ” ì‹ ê²½ë§
ì¼ë°˜ CNNì€ ë‹¤ìš´ìƒ˜í”Œë§ â†’ ì—…ìƒ˜í”Œë§ êµ¬ì¡°ë¥¼ ë”°ë¥´ì§€ë§Œ, HRNetì€ ë©€í‹° ìŠ¤ì¼€ì¼ featureë¥¼ ë³‘ë ¬ë¡œ ìœ ì§€í•¨

== ì¶”ê°€ ì„¤ëª… ==
=> CNNì€ í•´ìƒë„ë¥¼ ì¤„ì—¬ë‚˜ê°€ë©° ì •ë³´ ì¶”ì¶œ í›„ ë‹¤ì‹œ í•´ìƒë„ë¥¼ ë³µì› but ì´ ê³¼ì •ì—ì„œ ì •ë³´ ì†ì‹¤ì´ ë°œìƒ
=> HRNetì€ í•´ìƒë„ë¥¼ ì¤„ì´ì§€ ì•Šê³ , ê³ í•´ìƒë„ featureë¥¼ ëê¹Œì§€ ìœ ì§€í•˜ë©´ì„œ ë‹¤ì–‘í•œ í•´ìƒë„ì˜ ì •ë³´ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ê³ , ì§€ì†ì ìœ¼ë¡œ ì„œë¡œ êµí™˜í•¨.
=> ìµœì¢…ì ìœ¼ë¡œ ê³ í•´ìƒë„ ì¶œë ¥ ìœ ì§€

  * ë¸Œëžœì¹˜ : í•˜ë‚˜ì˜ ì‹ ê²½ë§ ì•ˆì—ì„œ ë³‘ë ¬ë¡œ ì¡´ìž¬í•˜ëŠ” ê²½ë¡œ ë˜ëŠ” êµ¬ì¡°

2. DeepLabV3+
ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¼ì˜ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ê²°í•©í•´ semantic segmentation(í”½ì…€ ë‹¨ìœ„ ê°ì²´ ë¶„ë¥˜) ì„±ëŠ¥ í–¥ìƒ
Atrous Convolution (Hole Convolution) ì„ í™œìš©í•˜ì—¬ downsampling ì—†ì´ receptive field í™•ìž¥
ASPP (Atrous Spatial Pyramid Pooling): ì„œë¡œ ë‹¤ë¥¸ dilation rateë¥¼ ê°€ì§„ ì—¬ëŸ¬ Conv layerë¥¼ ë³‘ë ¬ë¡œ ë°°ì¹˜
Decoder: DeepLabV3+ì—ì„œëŠ” decoder ëª¨ë“ˆ ì¶”ê°€ë¡œ ê²½ê³„ì„  ë³µì› ê°•í™”
'''

class HRNet_DeepLabV3(nn.Module):
    def __init__(self, hrnet_variant='hrnet_w18', out_dim=3):
        super().__init__()

        # 1. HRNet ë°±ë³¸ (features_only=True â†’ intermediate feature map ì¶”ì¶œ)
        self.hrnet = timm.create_model(
            hrnet_variant,
            pretrained=True,
            features_only=True  # ë§ˆì§€ë§‰ feature mapì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
        )

        # 2. DeepLabV3+ Head (ASPP + Decoder)
        # HRNet ë§ˆì§€ë§‰ ì±„ë„ ìˆ˜ í™•ì¸
        in_channels = self.hrnet.feature_info[-1]['num_chs']  # ì˜ˆ: 720 for hrnet_w18
        self.aspp_head = DeepLabHead(in_channels, 256)

        # 3. íšŒê·€ í—¤ë“œ
        self.regressor = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),  # GAP
            nn.Flatten(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, out_dim)  # ì˜ˆ: 3ê°œ ë¬¼ì„±ê°’
        )

    def forward(self, x):
        # HRNet backbone â†’ feature map list
        features = self.hrnet(x)
        feat = features[-1]  # ê°€ìž¥ ë§ˆì§€ë§‰ feature map ì‚¬ìš©

        # DeepLabV3+ ASPP Head
        x = self.aspp_head(feat)

        # íšŒê·€
        out = self.regressor(x)
        return out

# ==================================    
# csv ë°ì´í„° ì „ì²˜ë¦¬
# ==================================
'''
csv íŒŒì¼ì„ í™•ì¸í•´ë³´ë©´ ê³µëž€(ê²°ì¸¡ì¹˜)ê°€ ìžˆìŒ
ì´ëŠ” ë°ì´í„° ë³€í™˜ ì‹œ NaNìœ¼ë¡œ ì²˜ë¦¬ë˜ì–´ ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚´
ë”°ë¼ì„œ ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ í†µí•´ í•´ê²°í•´ì•¼ í•¨

ì‚¬ìš© ë°©ë²• : ë‹¤í•­ì‹ ë³´ê°„ (ploynomial Interpolation)
* ë³´ê°„ : ê²°ì¸¡ì¹˜ë‚˜ ì¤‘ê°„ì˜ ë¹ ì§„ ë°ì´í„°ë¥¼ ì±„ì›Œ ë„£ëŠ” ê¸°ë²•
* ë‹¤í•­ì‹ ë³´ê°„ ë°©ë²• :
  ì£¼ì–´ì§„ ë°ì´í„° í¬ì¸íŠ¸ë“¤ì„ í†µê³¼í•˜ëŠ” ë‹¤í•­ì‹(polynomial function)ì„ ë§Œë“¤ì–´, ê·¸ ë‹¤í•­ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ì¤‘ê°„ ê°’ì„ ì¶”ì •í•˜ëŠ” ë°©ë²•

=> ë°ì´í„° ê·¸ëž˜í”„ì˜ ê²½í–¥ì„ ë¶€ë“œëŸ½ê²Œ ì¶”ì¢…í•˜ëŠ” ê°’ì„ ì±„ì›Œë„£ìŒ
'''

# ìž…ë ¥ ë° ì¶œë ¥ ë””ë ‰í† ë¦¬
input_dir = "C:/Users/Admin/Desktop/2nd core sample dataset/log data"  # csv ë°ì´í„° í´ë” ì§€ì •
output_dir = "C:/Users/Admin/Desktop/2nd core sample dataset/Interpooled_data" # csv ë³´ê°„ ê²°ê³¼ë¥¼ ì €ìž¥í•  í´ë” ì§€ì •
os.makedirs(output_dir, exist_ok=True)

# ë³´ê°„ ëŒ€ìƒ ì—´ ë° xì¶•
columns_to_interpolate = ["pwave_vel", "density", "mag_sus"]
x_axis = "sb_depth_cm"

# ëª¨ë“  CSV ì²˜ë¦¬
csv_files = glob.glob(f"{input_dir}/*.csv")
print(f"ì´ {len(csv_files)}ê°œì˜ íŒŒì¼ ì²˜ë¦¬ ì¤‘...")

for file_path in csv_files:
    filename = os.path.basename(file_path).replace(".csv", "")
    print(f"ðŸ“„ ì²˜ë¦¬ ì¤‘: {filename}.csv")

    # 1. íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
    df = pd.read_csv(file_path)
    original_df = df.copy()

    # 2. ë‹¤í•­ì‹ ë³´ê°„
    for col in columns_to_interpolate:
        if df[col].isna().sum() > 0:
            df[col] = df[col].interpolate(method="polynomial", order=2)
            df[col] = df[col].ffill().bfill()

    # 3. í‘œì¤€í™” (ì›ë³¸/ë³´ê°„ ë°ì´í„° ëª¨ë‘)
    scaler = StandardScaler()
    original_df[columns_to_interpolate] = scaler.fit_transform(original_df[columns_to_interpolate])
    df[columns_to_interpolate] = scaler.fit_transform(df[columns_to_interpolate])

    # 4. ì‹œê°í™” (ì˜µì…˜)
    # for col in columns_to_interpolate:
    #     mv_before = original_df[col].isna().sum()
    #     mv_after = df[col].isna().sum()

    #     fig, axs = plt.subplots(1, 2, figsize=(14, 4), sharey=True)
    #     axs[0].plot(original_df[x_axis], original_df[col], marker='o', color='red')
    #     axs[0].set_title(f"[Before] {col} (NaNs: {mv_before})")
    #     axs[0].set_xlabel("Depth (cm)")
    #     axs[0].set_ylabel(col)
    #     axs[0].grid(True)

    #     axs[1].plot(df[x_axis], df[col], marker='o', color='blue')
    #     axs[1].set_title(f"[After] {col} (NaNs: {mv_after})")
    #     axs[1].set_xlabel("Depth (cm)")
    #     axs[1].grid(True)

    #     plt.tight_layout()
    #     plt.show()

    # 5. ì €ìž¥
    save_path = os.path.join(output_dir, f"{filename}_interpooled.csv")
    df.to_csv(save_path, index=False)
    print(f"âœ… ì €ìž¥ ì™„ë£Œ: {save_path}\n")


# ========== ì„¤ì • ==========
image_dir = "C:/Users/Admin/Desktop/2nd core sample dataset/raw image" # ì›ë³¸ ì´ë¯¸ì§€ ë°ì´í„° í´ë” ì§€ì •
csv_dir = "C:/Users/Admin/Desktop/2nd core sample dataset/Interpooled_data" # ë³´ê°„ëœ csv ë°ì´í„° í´ë” ì§€ì •
output_dir = "C:/Users/Admin/Desktop/2nd core sample dataset/matched_data" # ì´ë¯¸ì§€ì™€ csv ë°ì´í„°ë¥¼ ì—°ê²°í•œ ë°ì´í„°ë¥¼ ì €ìž¥í•  í´ë” ì§€ì •
os.makedirs(output_dir, exist_ok=True)

pixels_per_cm = 200  # 1cm = 200px (xml íŒŒì¼ í™•ì¸)

# ========== ì´ë¯¸ì§€ì™€ csv íŒŒì¼ êµ¬ë¶„ì„ ìœ„í•œ í™•ìž¥ìž ì´ë¦„ ì§€ì • í•¨ìˆ˜ ==========
def sort_by_section(img_list):
    def extract_number(name):
        return int(name.split("_")[-1].replace(".tif", ""))
    return sorted(img_list, key=extract_number)

def extract_core_id(name):
    parts = name.replace(".tif", "").replace(".csv", "").split("_")
    return "_".join(parts[2:4])  # "FA_GC01"

# ========== íŒŒì¼ ëª©ë¡ ì •ë¦¬ ==========
# 1. ì´ë¯¸ì§€
all_images = [f for f in os.listdir(image_dir) if f.endswith(".tif")]
image_map = {}
for img in all_images:
    core_id = extract_core_id(img)
    image_map.setdefault(core_id, []).append(img)

# 2. CSV
all_csvs = [f for f in os.listdir(csv_dir) if f.endswith(".csv")]
csv_map = {}
for csv in all_csvs:
    core_id = extract_core_id(csv)
    csv_map[core_id] = csv

# 3. ê³µí†µ core_idë§Œ ì¶”ì¶œ
image_core_ids = set(image_map.keys())
csv_core_ids = set(csv_map.keys())
common_ids = image_core_ids & csv_core_ids

# 4. ëˆ„ë½ëœ ë°ì´í„° í™•ì¸
image_only = image_core_ids - csv_core_ids
csv_only = csv_core_ids - image_core_ids

print("âŒ ì´ë¯¸ì§€ë§Œ ìžˆê³  CSV ì—†ëŠ” core_id:", sorted(image_only))
print("âŒ CSVë§Œ ìžˆê³  ì´ë¯¸ì§€ ì—†ëŠ” core_id:", sorted(csv_only))
print("âœ… ì²˜ë¦¬ ê°€ëŠ¥í•œ core_id ìˆ˜:", len(common_ids))

# 5. ì´ë¯¸ì§€ì™€ csv íŒŒì¼ì—ì„œ ëª…ì‹œëœ ê¸¸ì´ë¥¼ ë¹„êµí•˜ì—¬ ì „ì²˜ë¦¬
for core_id in tqdm(sorted(common_ids), desc="ðŸ” Core ìƒ˜í”Œ ì²˜ë¦¬"):
    # ----------------------
    # 1. ì´ë¯¸ì§€ ë³‘í•©
    # ----------------------
    merged_image = None
    sorted_imgs = sort_by_section(image_map[core_id])
    for fname in sorted_imgs:
        img_path = os.path.join(image_dir, fname)
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        merged_image = img if merged_image is None else np.vstack((merged_image, img))

    # ----------------------
    # 2. CSV ë¡œë“œ
    # ----------------------
    csv_path = os.path.join(csv_dir, csv_map[core_id])
    df = pd.read_csv(csv_path)
    target_cols = ["density", "pwave_vel", "mag_sus"]
    depth_col = "sb_depth_cm"

    # ----------------------
    # 3. ì´ë¯¸ì§€ ìŠ¬ë¼ì´ìŠ¤ ìˆ˜ ê³„ì‚°
    # ----------------------
    image_height_px = merged_image.shape[0]
    num_slices = image_height_px // pixels_per_cm
    image_depths = np.arange(num_slices)

    # ----------------------
    # 4. ë³´ê°„ ë˜ëŠ” ì ˆë‹¨
    # ----------------------
    if num_slices > len(df):
        print(f"ðŸŸ¢ {core_id}: ì´ë¯¸ì§€ê°€ ë” ê¸¸ì–´ì„œ ë³´ê°„ ìˆ˜í–‰")
        df_interp = pd.DataFrame({depth_col: image_depths})
        for col in target_cols:
            if df[col].isna().sum() > 0:
                df[col] = df[col].interpolate(method="polynomial", order=2)
                df[col] = df[col].ffill().bfill()
            f = interp1d(df[depth_col], df[col], kind='linear', fill_value="extrapolate")
            df_interp[col] = f(image_depths)
        df = df_interp

    elif num_slices < len(df):
        print(f"ðŸŸ¡ {core_id}: ì´ë¯¸ì§€ê°€ ë” ì§§ì•„ì„œ ìžë¦„")
        df = df.iloc[:num_slices].copy()

    df = df.dropna(subset=target_cols).reset_index(drop=True)

    # ----------------------
    # 5. ì´ë¯¸ì§€ ìŠ¬ë¼ì´ìŠ¤ ì €ìž¥
    # ----------------------
    sliced_image_paths = []
    core_output_dir = os.path.join(output_dir, core_id)
    os.makedirs(core_output_dir, exist_ok=True)

    for i in range(len(df)):  # ë³´ê°„ í›„ ê¸¸ì´ ê¸°ì¤€ìœ¼ë¡œ ìžë¦„
        y0 = i * pixels_per_cm
        y1 = (i + 1) * pixels_per_cm
        crop = merged_image[y0:y1, :]
        out_path = os.path.join(core_output_dir, f"{core_id}_slice_{i:03d}.png")
        cv2.imwrite(out_path, cv2.cvtColor(crop, cv2.COLOR_RGB2BGR))
        sliced_image_paths.append(out_path)

    # ----------------------
    # 6. ìµœì¢… CSV ì €ìž¥
    # ----------------------
    df["image_path"] = sliced_image_paths
    save_csv_path = os.path.join(core_output_dir, f"{core_id}_matched.csv")
    df.to_csv(save_csv_path, index=False)
    print(f"âœ… ì €ìž¥ ì™„ë£Œ: {core_id} â†’ {save_csv_path}")

# ë°ì´í„° ì„ ì–¸ í´ëž˜ìŠ¤
class CoreImageDataset(Dataset):
    def __init__(self, dataframe):
        self.df = dataframe.reset_index(drop=True)  # ðŸ’¡ DataFrame ì§ì ‘ ë°›ë„ë¡ ìˆ˜ì •
        self.image_paths = self.df["image_path"].values
        self.targets = self.df[["density", "pwave_vel", "mag_sus"]].values.astype("float32")
        self.transform = T.Compose([
            T.Resize((256, 256)),
            T.ToTensor(),
            T.Normalize(mean=[0.5]*3, std=[0.5]*3)
        ])

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        image = Image.open(self.image_paths[idx]).convert("RGB")
        image = self.transform(image)
        target = torch.tensor(self.targets[idx])
        return image, target

# -----------------------------
# ì„¤ì •
# -----------------------------
batch_size = 32 # ë°°ì¹˜ ì‚¬ì´ì¦ˆ : í•œ ë²ˆì˜ í•™ìŠµë™ì•ˆ ìž…ë ¥ë  ë°ì´í„°ì˜ ê°œìˆ˜
epochs = 50 # ì—í¬í¬ : ëª‡ ë²ˆì˜ í•™ìŠµì„ ë°˜ë³µí• ì§€ ì„¤ì •
lr = 1e-4 # í•™ìŠµë¥  : íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ì˜ ì†ë„ ì„¤ì •
                  # ë„ˆë¬´ í¬ë©´ ë°œì‚°í•˜ì—¬ ì ì ˆí•œ íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì§€ ëª»í•¨ & ë„ˆë¬´ ìž‘ìœ¼ë©´ í•™ìŠµ ì†ë„ê°€ ëŠë ¤ì§
out_dim = 3  # íšŒê·€ ëŒ€ìƒ ìˆ˜ (ë°€ë„, ì†ë„, ìžì„± ë“± ë¬¼ì„± columnì˜ ê°œìˆ˜ë¥¼ ì§€ì •)

# gpuê°€ ìžˆìœ¼ë©´ gpu ì‚¬ìš©, ì—†ìœ¼ë©´ cpu ì‚¬ìš©
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# -----------------------------
# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
# -----------------------------
matched_root = "C:/Users/Admin/Desktop/2nd core sample dataset/matched_data"
all_core_ids = sorted(os.listdir(matched_root))

train_dfs, val_dfs, test_dfs = [], [], []

for core_id in all_core_ids:
    matched_csv = os.path.join(matched_root, core_id, f"{core_id}_matched.csv")
    if not os.path.exists(matched_csv):
        continue

    df = pd.read_csv(matched_csv)

    # core_id ì—´ ì¶”ê°€
    df["core_id"] = core_id

    # ìŠ¬ë¼ì´ìŠ¤ ë‹¨ìœ„ ë¶„í• 
    train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, shuffle=True)
    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)  # val 15%, test 15%

    train_dfs.append(train_df)
    val_dfs.append(val_df)
    test_dfs.append(test_df)

# ì „ì²´ ë°ì´í„°í”„ë ˆìž„ í†µí•©
train_df = pd.concat(train_dfs, ignore_index=True)
val_df = pd.concat(val_dfs, ignore_index=True)
test_df = pd.concat(test_dfs, ignore_index=True)

print(f"Train samples: {len(train_df)}")
print(f"Val samples  : {len(val_df)}")
print(f"Test samples : {len(test_df)}")

# 4. Dataset / DataLoader ìƒì„±
train_ds = CoreImageDataset(train_df)
val_ds = CoreImageDataset(val_df)
test_ds = CoreImageDataset(test_df)

train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)
val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)
test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)

print(f"Train: {len(train_ds)} | Val: {len(val_ds)} | Test: {len(test_ds)}")

# -----------------------------
# ëª¨ë¸ ì •ì˜
# -----------------------------
model = HRNet_DeepLabV3(hrnet_variant='hrnet_w18', out_dim=out_dim)
model = model.to(device)

# -----------------------------
# ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €
# -----------------------------
loss_fn = nn.MSELoss() # í‰ê· ì œê³±ì˜¤ì°¨ë¥¼ ê¸°ì¤€ìœ¼ë¡œ Loss ê³„ì‚°
optimizer = optim.Adam(model.parameters(), lr=lr)

# -----------------------------
# í•™ìŠµ ë£¨í”„
# -----------------------------
for epoch in range(epochs):
    model.train()
    total_loss = 0
    all_preds = []
    all_targets = []

    for images, targets in tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}"):
        images = images.to(device)
        targets = targets.to(device)

        preds = model(images)

        if torch.isnan(preds).any():
            print("NaN in preds! Skipping batch.")
            continue

        loss = loss_fn(preds, targets)

        if torch.isnan(loss):
            print("NaN in loss! Skipping batch.")
            continue

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        all_preds.append(preds.detach().cpu().numpy())
        all_targets.append(targets.cpu().numpy())

    # ê²°ê³¼ ì¶œë ¥
    all_preds = np.vstack(all_preds)
    all_targets = np.vstack(all_targets)

    mse = mean_squared_error(all_targets, all_preds)
    rmse = np.sqrt(mse)
    r2 = r2_score(all_targets, all_preds)

    # Loss : ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ì‚¬ì´ì˜ ì˜¤ì°¨ë¥¼ ìˆ˜ì¹˜ë¡œ ë‚˜íƒ€ë‚¸ ê²ƒ (ìž‘ì„ìˆ˜ë¡ ì¢‹ìŒ)
    # RMSE : MSEì˜ ì œê³±ê·¼ì„ ì·¨í•œ ê°’ (= í˜„ìž¬ Lossê°€ MSELossì´ê¸° ë•Œë¬¸ì— Lossì˜ ì œê³±ê·¼ ê°’ìž„) (ìž‘ì„ìˆ˜ë¡ ì¢‹ìŒ)
    # R square(ê²°ì •ê³„ìˆ˜) : ëª¨ë¸ì´ ì‹¤ì œ ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ìž˜ ì„¤ëª…í•˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œ (í´ìˆ˜ë¡ ì¢‹ìŒ)
    print(f"[Epoch {epoch+1}/{epochs}] Loss: {total_loss/len(train_loader):.4f} | RMSE: {rmse:.3f} | RÂ²: {r2:.3f}\n")

# í•™ìŠµ ì™„ë£Œëœ ëª¨ë¸ ì €ìž¥
torch.save(model.state_dict(), "hrnet_dlv3_regression.pth")

# -----------------------------
# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ë° í‰ê°€
# -----------------------------
model = HRNet_DeepLabV3(hrnet_variant='hrnet_w18', out_dim=3)  # ì•„í‚¤í…ì²˜ ë°˜ë“œì‹œ ë™ì¼í•˜ê²Œ
model.load_state_dict(torch.load("hrnet_dlv3_regression.pth"), strict = False)
model = model.to(device)
model.eval()
y_true = []
y_pred = []

with torch.no_grad():
    for images, targets in test_loader:
        images = images.to(device)
        outputs = model(images).cpu().numpy()
        y_pred.append(outputs)
        y_true.append(targets.numpy())

y_true = np.vstack(y_true)
y_pred = np.vstack(y_pred)

# -----------------------------
# ì •ëŸ‰ ì§€í‘œ ê³„ì‚°
# -----------------------------
mse = mean_squared_error(y_true, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_true, y_pred)

print("========================")
print("ðŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ (ì •ëŸ‰ ì§€í‘œ)")
print(f"ðŸ”¹ MSE : {mse:.4f}")
print(f"ðŸ”¹ RMSE: {rmse:.4f}")
print(f"ðŸ”¹ RÂ²  : {r2:.4f}")
print("========================")

# -----------------------------
# ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’ ê·¸ëž˜í”„
# -----------------------------
feature_names = ["Density", "P-wave Velocity", "Magnetic Susceptibility"]
num_features = y_true.shape[1]  # ë³´í†µ 3ê°œ

plt.figure(figsize=(18, 5))

for i in range(num_features):
    plt.subplot(1, 3, i + 1)
    plt.plot(y_true[:, i], label="True", color="blue", marker="o")
    plt.plot(y_pred[:, i], label="Pred", color="red", linestyle="--", marker="x")
    plt.title(f"{feature_names[i]} (per Slice)")
    plt.xlabel("Slice Index (1cm units)")
    plt.ylabel(feature_names[i])
    plt.grid(True)
    plt.legend()

plt.tight_layout()
plt.show()